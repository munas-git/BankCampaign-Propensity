{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1570881,"sourceType":"datasetVersion","datasetId":223954}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Context\nTerm deposits are a key income source for banks, and telephonic marketing remains one of the most effective ways to sell them. However, these campaigns are resource-intensive, involving large call centers. To optimize efficiency, it's crucial to identify customers who are most likely to convert before reaching out. [This dataset](https://www.kaggle.com/datasets/prakharrathi25/banking-dataset-marketing-targets/data) is related to direct telephonic marketing campaigns of a Portuguese bank, with the goal of predicting whether a customer will subscribe to a term deposit (yes/no). ***My own personal objectives are listed below.***\n\n## Objectives\n- Evaluate effectiveness of past campaign... Past Conversion Rate.\n- Understand the nature of factors that actually drive conversion\n- Build a propensity model to estimate likelihood of future conversion for similar campaign.\n- Calibrate model to better reflect probabilities\n- Identify top percentage of leads expected to convert, without triggering diminishing returns.\n- Measure gains and uplift\n- Design and recommend data-informed A/B experiments strategies. \n\n**NOTE**: This entire analysis is part of my weekly series in efforts to **demystify applied statistical techniques through real-world, project-driven examples**, making concepts like propensity modelling, causal inference, and evaluation metrics more accessible to practitioners of all backgrounds.\n\nLet's connect! --> [LinkedIn](https://www.linkedin.com/in/einstein-ebereonwu/) | [X](https://x.com/einsteinmuna) | [GitHub.](https://github.com/munas-git)","metadata":{}},{"cell_type":"markdown","source":"# Importing Important Libraries","metadata":{}},{"cell_type":"code","source":"!pip install rich==13.7.1 toolz==0.11.2 scikit-learn==1.4.0 imbalanced-learn==0.12.0 --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:33.824898Z","iopub.execute_input":"2025-05-02T12:08:33.825245Z","iopub.status.idle":"2025-05-02T12:08:37.546744Z","shell.execute_reply.started":"2025-05-02T12:08:33.825223Z","shell.execute_reply":"2025-05-02T12:08:37.545439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data wrangling\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Data vis\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Model training & evaluation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    precision_score, recall_score, confusion_matrix,\n    roc_auc_score, roc_curve, precision_recall_curve,\n    classification_report)\n\n# Model explainability\nimport shap\n\n# Data augmentation\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n\n# Model calibration\nfrom sklearn.metrics import brier_score_loss\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.calibration import CalibratedClassifierCV, calibration_curve\n\n# Handling warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.548557Z","iopub.execute_input":"2025-05-02T12:08:37.548878Z","iopub.status.idle":"2025-05-02T12:08:37.556786Z","shell.execute_reply.started":"2025-05-02T12:08:37.548852Z","shell.execute_reply":"2025-05-02T12:08:37.555875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/banking-dataset-marketing-targets/train.csv\", sep=\";\")\n\n# The dataset description says -->\n# test.csv: 4521 rows and 18 columns with 10% of the examples (4521)\n# randomly selected from train.csv\n\n# For the reason above, I am not working with test.csv at all due to data leakage concerns.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.558211Z","iopub.execute_input":"2025-05-02T12:08:37.558513Z","iopub.status.idle":"2025-05-02T12:08:37.708937Z","shell.execute_reply.started":"2025-05-02T12:08:37.558487Z","shell.execute_reply":"2025-05-02T12:08:37.707724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.711107Z","iopub.execute_input":"2025-05-02T12:08:37.711447Z","iopub.status.idle":"2025-05-02T12:08:37.728133Z","shell.execute_reply.started":"2025-05-02T12:08:37.711424Z","shell.execute_reply":"2025-05-02T12:08:37.727093Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Some EDA","metadata":{"execution":{"iopub.status.busy":"2025-04-30T12:33:49.852941Z","iopub.execute_input":"2025-04-30T12:33:49.853237Z","iopub.status.idle":"2025-04-30T12:33:49.857355Z","shell.execute_reply.started":"2025-04-30T12:33:49.853214Z","shell.execute_reply":"2025-04-30T12:33:49.856488Z"}}},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.729128Z","iopub.execute_input":"2025-05-02T12:08:37.729398Z","iopub.status.idle":"2025-05-02T12:08:37.780723Z","shell.execute_reply.started":"2025-05-02T12:08:37.729377Z","shell.execute_reply":"2025-05-02T12:08:37.779729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.781553Z","iopub.execute_input":"2025-05-02T12:08:37.781837Z","iopub.status.idle":"2025-05-02T12:08:37.817267Z","shell.execute_reply.started":"2025-05-02T12:08:37.781817Z","shell.execute_reply":"2025-05-02T12:08:37.816407Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation**   \nBefore even going further, It's worth discussing some extreme values, my assumptions, why and how I am handling some very extreme values.\n\n- ***age:*** Upon further review, the dataset consists of people between 80 - 90+ who also get/don't get the term deposit, and I guess a 95 year could plausibly get a term deposits as some sort of inheritance so I will keep this observation. \n- ***balance:*** A quick gogle search reviewed the following `Yes, Portugal experienced a financial crisis between May 2008 and November 2010` which is the record yer of this dataset so a negatie balance that high is also quite plausible.\n- ***duration:*** The dataset metadata describes duration as `last contact duration, in seconds (numeric)`. I don't know about you, but I would never be on a marketing call for *4918* seconds which equates to 81 minutes. I am dropping every observation this extreme.\n- ***campaign:*** described as `number of contacts performed during this campaign and for this client (numeric, includes last contact)`. The mean contact is 2 with a reasonable standard deviation, and 75th percentile of 3. 63 contacts (calls) just seems impossible, I will be dropping observations this extreme.\n- ***pdays:*** Defined as `number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)`. I will leave no contact as -1 and temporarily allow last campaign contact that extreme (more than 2 years ago). If I notice significant damage in propensity model, I will also exclude such extreme values.\n- ***previous:*** Defined as `number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)`. When I sorted the dataset in descending order of previous, I noticed only 1 extreme outlier. I am excluding this from the rest of my work.","metadata":{}},{"cell_type":"code","source":"# Use this to observe top or bottom values of the data columns to\n# further understand my reasons for the actions above.\n\ncolumn_name = 'previous'\nnumbers_to_return = 3\ntop_bottom = 2 # specify 1 for ascending order sort and 2 for descending order.. Defaults to Ascending. \n\ntrain_df.sort_values(by = column_name, ascending = True if top_bottom == 1 else False if top_bottom == 2 else 1).head(numbers_to_return)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.818117Z","iopub.execute_input":"2025-05-02T12:08:37.818349Z","iopub.status.idle":"2025-05-02T12:08:37.842065Z","shell.execute_reply.started":"2025-05-02T12:08:37.818333Z","shell.execute_reply":"2025-05-02T12:08:37.841149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Handling the outliers from above\n\n# Drop rows where duration exceeds 99.9th percentile\nduration_99p9th = train_df['duration'].quantile(0.999)\nprint(f'Cut off value is {duration_99p9th}')\nprint(f'Number of *duration* outliers: {len(train_df[train_df[\"duration\"] >= duration_99p9th])}\\n')\ntrain_df = train_df[train_df['duration'] <= duration_99p9th]\n\n# Drop rows where campaign exceeds the 99.9th percentile\ncampaign_99p9th = train_df['campaign'].quantile(0.999)\nprint(f'Cut off value is {campaign_99p9th}')\nprint(f'Number of *campaign* outliers: {len(train_df[train_df[\"campaign\"] >= campaign_99p9th])}\\n')\ntrain_df = train_df[train_df['campaign'] <= campaign_99p9th]\n\n# Drop the single max row\nprevious_max = train_df['previous'].max()\nprint(f'Cut off value is {previous_max}')\nprint(f'Number of *previous* outliers: {len(train_df[train_df[\"previous\"] == previous_max])}\\n')\ntrain_df = train_df[train_df['previous'] < previous_max]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.842927Z","iopub.execute_input":"2025-05-02T12:08:37.843154Z","iopub.status.idle":"2025-05-02T12:08:37.879652Z","shell.execute_reply.started":"2025-05-02T12:08:37.843137Z","shell.execute_reply":"2025-05-02T12:08:37.878650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.880534Z","iopub.execute_input":"2025-05-02T12:08:37.880875Z","iopub.status.idle":"2025-05-02T12:08:37.915595Z","shell.execute_reply.started":"2025-05-02T12:08:37.880848Z","shell.execute_reply":"2025-05-02T12:08:37.914354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.sort_values(by = 'duration', ascending = False).head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.919048Z","iopub.execute_input":"2025-05-02T12:08:37.919349Z","iopub.status.idle":"2025-05-02T12:08:37.945104Z","shell.execute_reply.started":"2025-05-02T12:08:37.919328Z","shell.execute_reply":"2025-05-02T12:08:37.944379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation**   \nEverything makes much more sense now... The `max duration` is still kind of high at 2087 seconds ~= 35 minutes but I will accept that under the guise that the person on the receiving end was just curious about all the details and wanted to know exactly what they were getting into.\n\nIf you notice, the person who had the longest call holds a ***manager*** level job so it makes sense that they are quizing the marketer and want to know as much information before making a strategic financial decision. Their balance is quite low which is suspecious but the person may have other bank accounts while this one is strictly for very small expenses, assuming the amount column isnt expressed in thousands. Same with the blue-collar worked who follows after. The person doesn't seem to have much money so would be wise to know all details before taking the financial decision.","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.945974Z","iopub.execute_input":"2025-05-02T12:08:37.946285Z","iopub.status.idle":"2025-05-02T12:08:37.983723Z","shell.execute_reply.started":"2025-05-02T12:08:37.946259Z","shell.execute_reply":"2025-05-02T12:08:37.982758Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating effectiveness of past campaign","metadata":{}},{"cell_type":"code","source":"past_conversion = train_df['y'].value_counts(normalize=True).values[1]\nprint(f'The conversion rate for the past campaign was {past_conversion * 100:.3}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:37.984859Z","iopub.execute_input":"2025-05-02T12:08:37.985186Z","iopub.status.idle":"2025-05-02T12:08:38.003036Z","shell.execute_reply.started":"2025-05-02T12:08:37.985159Z","shell.execute_reply":"2025-05-02T12:08:38.002021Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Note**   \n10% - 12% is a reasonable conversion rate for random targeting... Let's investigate what this looks like across the different covariates.","metadata":{}},{"cell_type":"code","source":"categorical_columns = train_df.select_dtypes(include = ['object']).columns.drop('y')\n\nsns.set(style = \"whitegrid\")\nplt.figure(figsize = (12, 12))\n\nfor i, col in enumerate(categorical_columns, 1):\n    plt.subplot(3, 3, i)\n    sns.countplot(x = col, hue = 'y', data = train_df)\n    plt.title(f'{col.title()} vs Subscription to Term Deposit')\n    plt.xlabel(col)\n    plt.ylabel('Count')\n    plt.xticks(rotation = 45, ha = 'right')\n    plt.legend(title = 'Subscription', labels = ['No', 'Yes'])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:38.004041Z","iopub.execute_input":"2025-05-02T12:08:38.004295Z","iopub.status.idle":"2025-05-02T12:08:40.502612Z","shell.execute_reply.started":"2025-05-02T12:08:38.004275Z","shell.execute_reply":"2025-05-02T12:08:40.501712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observations**   \n\nFor the categorical columns above:\n- ***Job***: Those assuming managerial positions converted the most as a result of the past campaign, while those who are entrepreneurs or housemaids converted the least.\n\n- ***Marital***: Single individuals had the highest term deposit subscription rate, while divorced individuals had the lowest.\n\n- ***Education***: Individuals with tertiary education had the highest subscription rate, while those with primary education had the lowest.\n\n- ***Default***: Clients with no credit default had significantly higher subscriptions; those with defaults rarely subscribed.\n\n- ***Housing***: Clients without housing loans subscribed more compared to those with housing loans.\n\n- ***Loan***: Clients without personal loans had the highest subscription rate, whereas those with personal loans subscribed much less.\n\n- ***Contact***: Clients contacted via cellular phones subscribed the most, while those contacted via telephone had the lowest turnout.\n\n- ***Month***: The month of May saw the highest number of subscriptions, while March and December had the lowest.\n\n- ***Poutcome***: Clients with a successful previous campaign outcome had the highest subscription rate; those with an outcome marked \"failure\" or \"other\" had lower turnout, and those with \"unknown\" had the least.","metadata":{}},{"cell_type":"code","source":"int_columns = train_df.select_dtypes(include = ['int64']).columns\n\nn_cols = 3\nn_rows = int(np.ceil(len(int_columns) / n_cols))\n\nplt.figure(figsize=(n_cols * 5, n_rows * 4))\n\nfor i, col in enumerate(int_columns, 1):\n    plt.subplot(n_rows, n_cols, i)\n    sns.histplot(data = train_df, x = col, hue = 'y', bins = 30, kde = True,\n                 palette = 'Set2', element = 'step', stat = 'density', common_norm = False)\n    plt.title(f'{col.title()} by Subscription to Term Deposit')\n    plt.xlabel(col)\n    plt.ylabel('Density')\n    plt.tight_layout()\n\nplt.suptitle('Integer Feature Distributions by Subscription Outcome', fontsize = 16, y = 1.02)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:40.503846Z","iopub.execute_input":"2025-05-02T12:08:40.504203Z","iopub.status.idle":"2025-05-02T12:08:46.351623Z","shell.execute_reply.started":"2025-05-02T12:08:40.504174Z","shell.execute_reply":"2025-05-02T12:08:46.350718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observations**   \n\nFor the numerical columns above:\n- ***Age***: Subscribers were generally older than non-subscribers, with a noticeable density in the 30–60 age range for successful subscriptions.\n\n- ***Balance***: Clients with higher account balances showed a higher likelihood of subscribing; non-subscribers were concentrated around lower balances.\n\n- ***Day***: There is no strong trend across days of the month; both subscribers and non-subscribers are relatively evenly distributed.\n\n- ***Duration***: Call duration is highly influential, longer call durations were strongly associated with successful subscriptions.\n\n- ***Campaign***: Fewer campaign contacts (1–3 times) were more effective; the probability of subscription decreased as the number of contacts increased.... That is sensible because if they didn't subscribe during 3 contacts then it's probably because they are really not interested.\n\n- ***Pdays***: A high subscription rate is observed when clients had been contacted recently (low pdays values), howeverrr.. some people still convert even after pro-longed periods of no contact, this suggests strong interest/motivation independent of contact recency, or some other factors maybe improved product knowledge, financial goals, friends influence? who knows..\n\n\n- ***Previous***: Those who had been contacted fewer times in past campaigns (especially 1–2 times) had higher success rates. The probability drops with increasing previous contacts.\n","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Encoding all categorical variables.\n# Excluding education and month because education level is ordinal data.\n# Same as month. Instead of one-hot or categorical, I will \n# use 1 - 12 because the kde for months/target shows seasonal trend.\n\ndef preprocess_data(train_df, target_col = 'y'):\n    non_ordinal_categorical_columns = categorical_columns.drop(['education', 'month'])\n    \n    # Dictionary to store fitted label encoders\n    label_encoders = {}\n    \n    # Process non-ordinal categorical columns\n    for col in non_ordinal_categorical_columns:\n        le = LabelEncoder()\n        train_df[col] = le.fit_transform(train_df[col])\n        label_encoders[col] = le\n\n    # Ordinal mappings\n    month_order = {\n        'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n        'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n    \n    education_mapping = {\n        'primary': 0, 'secondary': 1,\n        'tertiary': 2, 'unknown': -1}\n\n    # Apply ordinal mappings\n    train_df['month'] = train_df['month'].map(month_order)\n    train_df['education'] = train_df['education'].map(education_mapping)\n\n    # Encode target variable\n    train_df[target_col] = train_df[target_col].apply(lambda x: 1 if x == 'yes' else 0)\n    \n    return train_df, label_encoders\n\n\ntrain_df, label_encoders = preprocess_data(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:46.352775Z","iopub.execute_input":"2025-05-02T12:08:46.353510Z","iopub.status.idle":"2025-05-02T12:08:46.452423Z","shell.execute_reply.started":"2025-05-02T12:08:46.353478Z","shell.execute_reply":"2025-05-02T12:08:46.451497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# All categorical info have now been encoded and ready for propensity modelling\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:46.453370Z","iopub.execute_input":"2025-05-02T12:08:46.453726Z","iopub.status.idle":"2025-05-02T12:08:46.466380Z","shell.execute_reply.started":"2025-05-02T12:08:46.453675Z","shell.execute_reply":"2025-05-02T12:08:46.465451Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Understand the nature of factors that actually drive conversion","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(columns='y')\ny = train_df['y']\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size = 0.2,\n    random_state = 42,\n    stratify = y)\n\nX_train, X_calib, y_train, y_calib = train_test_split(\n    X_train, y_train,\n    test_size = 0.2,\n    random_state = 42,\n    stratify = y_train)\n\nprint(f'Train Set split: {y_train.value_counts()}')\nprint(f'\\nCalibration Set split: {y_calib.value_counts()}')\nprint(f'\\nTest Set split: {y_test.value_counts()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:46.467456Z","iopub.execute_input":"2025-05-02T12:08:46.467741Z","iopub.status.idle":"2025-05-02T12:08:46.539425Z","shell.execute_reply.started":"2025-05-02T12:08:46.467721Z","shell.execute_reply":"2025-05-02T12:08:46.538700Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training model for initial feature relevance & performance observation","metadata":{"execution":{"iopub.status.busy":"2025-05-01T16:07:09.755694Z","iopub.execute_input":"2025-05-01T16:07:09.756009Z","iopub.status.idle":"2025-05-01T16:07:09.760448Z","shell.execute_reply.started":"2025-05-01T16:07:09.755986Z","shell.execute_reply":"2025-05-01T16:07:09.759273Z"}}},{"cell_type":"code","source":"# This is just to get a rough understanding of what factors influence models understanding\n# Of the data.... I will train a better optimised model based on the results obtained here\n\nrf_model = RandomForestClassifier(\n    n_estimators = 300,\n    max_depth = 10,\n    class_weight = 'balanced',\n    random_state = 42\n)\nrf_model.fit(X_train, y_train)\n\ny_pred = rf_model.predict(X_test)\ny_proba = rf_model.predict_proba(X_test)[:, 1]\n\nconf_matrix = confusion_matrix(y_test, y_pred)\nfpr, tpr, _ = roc_curve(y_test, y_proba)\nroc_auc = roc_auc_score(y_test, y_proba)\nprecision, recall, _ = precision_recall_curve(y_test, y_proba)\n\nprint(f'\\nClassification Report:\\n {classification_report(y_test, y_pred)}\\n\\n')\n\nplt.figure(figsize = (18, 5))\nplt.subplot(1, 3, 1)\nsns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = 'Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\nplt.subplot(1, 3, 2)\nplt.plot(fpr, tpr, label = f'AUC = {roc_auc:.2f}', color = 'darkorange')\nplt.title('ROC Curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 3, 3)\nplt.plot(recall, precision, color='green')\nplt.title('Precision-Recall Curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:46.540363Z","iopub.execute_input":"2025-05-02T12:08:46.540713Z","iopub.status.idle":"2025-05-02T12:08:56.206244Z","shell.execute_reply.started":"2025-05-02T12:08:46.540663Z","shell.execute_reply":"2025-05-02T12:08:56.205363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation**   \nWell! The class imbalance is clearly heavily affecting the ***classification*** performance of the model as made clear by the discrepancy between the recall and precision of the model between both classes.\n\nHowever, the goal isn't classification, it's ***lead scoring*** and the model has a high AUC meaning that it consistently ranks those who converted higher than those who didn't. It also has a relatively high recall at the cost of more false-positives, which is talk for classification.\n\nAfter the subsequent steps mentioned below (especially alignment), I will checkout the gains and lift to see if they're reasonable and if I'm satisfied with them. If not, I will explore data augmentation (over & undersampling). I already explored model selection in cells now deleted, and the best performances were relatively similar to that of the rf model used.\n\n\n**Subsequently**\n- I will create a SHAP plot to see what this naive model says about decision influencing factors\n- I will align predicted propensity scores with ideal values and plot reliability graph before/after alignment \n- I will assign propensity scores and continue with gains and lift related work\n\nIf you want to better understand what stories preciaion and recall tell, you are welcome to checkout [this post](https://www.linkedin.com/posts/einstein-ebereonwu_%F0%9D%90%8F%F0%9D%90%AB%F0%9D%90%9E%F0%9D%90%9C%F0%9D%90%A2%F0%9D%90%AC%F0%9D%90%A2%F0%9D%90%A8%F0%9D%90%A7-%F0%9D%90%A8%F0%9D%90%AB-%F0%9D%90%91%F0%9D%90%9E%F0%9D%90%9C%F0%9D%90%9A%F0%9D%90%A5%F0%9D%90%A5-%F0%9D%90%96%F0%9D%90%A1%F0%9D%90%9A%F0%9D%90%AD-activity-7323300180882079744-4q8y?utm_source=share&utm_medium=member_desktop&rcm=ACoAACfSx2YBBgHwK5o8dtbmATIL2EtooLGRKYY). The model ","metadata":{}},{"cell_type":"code","source":"base_rf_explainer = shap.Explainer(rf_model)\nshap_values = base_rf_explainer(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:08:56.207295Z","iopub.execute_input":"2025-05-02T12:08:56.207563Z","iopub.status.idle":"2025-05-02T12:16:08.812230Z","shell.execute_reply.started":"2025-05-02T12:08:56.207543Z","shell.execute_reply":"2025-05-02T12:16:08.811225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shap_values_class1 = shap_values[..., 1] #<-- actually just learnt about the use of elipse.\nshap.plots.beeswarm(shap_values_class1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:16:08.813121Z","iopub.execute_input":"2025-05-02T12:16:08.813363Z","iopub.status.idle":"2025-05-02T12:16:09.835093Z","shell.execute_reply.started":"2025-05-02T12:16:08.813343Z","shell.execute_reply":"2025-05-02T12:16:09.834215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mapping values for context\nhousing_mapping = {cls: i for i, cls in enumerate(label_encoders['housing'].classes_)}\ncontact_mapping = {cls: i for i, cls in enumerate(label_encoders['contact'].classes_)}\nprint(f'Housing loan?: {housing_mapping}')\nprint(f'Contact mtd. mapping: {contact_mapping}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:16:09.836142Z","iopub.execute_input":"2025-05-02T12:16:09.836428Z","iopub.status.idle":"2025-05-02T12:16:09.842267Z","shell.execute_reply.started":"2025-05-02T12:16:09.836400Z","shell.execute_reply":"2025-05-02T12:16:09.841312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation**  \n\nThe SHAP plot above provides a more detailed explanation of feature contributions compared to the correlation plots from few cells above. It shows the most releant features according to the model, as well as the effect of low/high values of them.\n\n- ***Duration***: is the most influential feature. Longer call durations significantly increase the likelihood of a client subscribing. Almost all high-duration interactions contribute positively to the model output, indicating a strong association between longer calls and successful subscriptions.\n\n- ***Housing***: clients without a housing loan are more likely to subscribe. The model assigns positive SHAP values to such individuals, suggesting that not having a housing loan correlates with a greater chance of conversion.\n\n- ***Month***: the month of contact shows varied influence. Some months (likely those with higher values i.e May - December) are positively associated with subscription, while others are not. Could be a seasonal trend thing...\n\n- ***Contact***: the method of contact (cellular, telephone, or unknown) impacts subscription likelihood. Those contacted by cellular are more likely to convert. \n\n- ***Pdays***: lower values (recent contact) tend to decrease the likelihood of subscription, while higher values (less recent contact or no contact) are associated with positive SHAP values, suggesting that too frequent prior contact may reduce effectiveness... Let's not forget the recall of the model. This may be a misunderstanding and why the model is performing badly. Who knows..\n\n- ***Age***: older clients tend to have slightly more positive SHAP values. This makes sense, as middle-aged or older clients are more likely to subscribe, seeing it as a solid long-term investment.\n\n- ***Previous***: a higher number of contacts in previous campaigns slightly increases the likelihood of conversion... Maybe they finally warmed up to the product.\n\n- ***Poutcome***: a successful outcome of a previous campaign contributes positively to the prediction. Clients with past positive responses are more likely to subscribe again... Loyal people <3\n\n- ***Day***: early days of month seem to have a slightly higher probability of conversion while some mid-late days also have some level of positive effect. Maybe those are days within special months correlating with the seasons?a\n\n- ***Other Features***: the other features still contribute cumulatively to the model’s decision-making process... Will experiment with and without those features to measure performance.   \n\n\n**Reccomendations** \nThe information above could be used for future A/B testing, reaching out to older/younger, prople who converted in the past/those who didn't, those with/without housing loan. e.t.c.","metadata":{}},{"cell_type":"markdown","source":"## Checking effect of model calibration","metadata":{}},{"cell_type":"code","source":"calibrated_model = CalibratedClassifierCV(rf_model, cv = 'prefit', method = 'sigmoid')\ncalibrated_model.fit(X_calib, y_calib)\n\ny_proba_uncalibrated = rf_model.predict_proba(X_test)[:, 1]\ny_proba_calibrated = calibrated_model.predict_proba(X_test)[:, 1]\n\nplt.figure(figsize = (8, 6))\nprob_true_before, prob_pred_before = calibration_curve(y_test, y_proba_uncalibrated, n_bins = 10)\nprob_true_after, prob_pred_after = calibration_curve(y_test, y_proba_calibrated, n_bins = 10)\n\nplt.plot(prob_pred_before, prob_true_before, marker = 'x', label = 'Before Calibration', color = 'blue')\nplt.plot(prob_pred_after, prob_true_after, marker = 'o', label = 'After Calibration', color = 'green')\nplt.plot([0, 1], [0, 1], linestyle = '--', label = 'Ideal', color = 'red')\n\nplt.title('Reliability Diagram (Before and After Calibration)')\nplt.xlabel('Predicted Probability')\nplt.ylabel('Empirical Probability')\nplt.legend()\nplt.grid(True)\n\nbrier_before = brier_score_loss(y_test, y_proba_uncalibrated)\nbrier_after = brier_score_loss(y_test, y_proba_calibrated)\nprint(f'Brier score before calibration: {brier_before:.4f}')\nprint(f'Brier score after calibration: {brier_after:.4f}')\nprint(f'Improvement: {(1 - brier_after/brier_before) * 100:.2f}%')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:16:09.843225Z","iopub.execute_input":"2025-05-02T12:16:09.843543Z","iopub.status.idle":"2025-05-02T12:16:10.927115Z","shell.execute_reply.started":"2025-05-02T12:16:09.843514Z","shell.execute_reply":"2025-05-02T12:16:10.926248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation**  \n\nCalibration has great effect on the predicted probabilities, thus, I will go ahead to assign propensity scores with the calibrated model as that better reflects reality.","metadata":{}},{"cell_type":"markdown","source":"# Training final model and continuing with lead scoring","metadata":{}},{"cell_type":"code","source":"# Final model on all data, excluding calibration set\n# since calibration had quite the impact when I was trying to\n# understand model performance\n\nX_combined = pd.concat([X_train, X_test], axis = 0)\ny_combined = pd.concat([y_train, y_test], axis = 0)\nall_data_excluding_calib = pd.concat([X_combined, y_combined], axis = 1)\n\nrf_prop_model = RandomForestClassifier(\n    n_estimators = 300,\n    max_depth = 10,\n    class_weight = 'balanced',\n    random_state = 42)\nrf_prop_model.fit(X_combined, y_combined)\n\ncalibrated_model = CalibratedClassifierCV(rf_prop_model, cv = 'prefit', method = 'sigmoid')\ncalibrated_model.fit(X_calib, y_calib)\n\n\n# Assigning calibrated lead scores\nall_data_excluding_calib['lead_score'] = calibrated_model.predict_proba(all_data_excluding_calib.drop('y', axis = 1))[:, 1]\nscored_df = all_data_excluding_calib.sort_values('lead_score', ascending = False)\nscored_df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:16:10.928145Z","iopub.execute_input":"2025-05-02T12:16:10.928915Z","iopub.status.idle":"2025-05-02T12:16:23.229999Z","shell.execute_reply.started":"2025-05-02T12:16:10.928893Z","shell.execute_reply":"2025-05-02T12:16:23.229046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_positives = y.sum()\n\npercentiles = np.linspace(0.01, 1, 100)\nrandom_gain = (total_positives / len(scored_df)) * 100\ngains = []\nlifts = []\n\n\nfor top_percent in percentiles:\n    top_n = int(len(scored_df) * top_percent)\n    top_leads = scored_df.head(top_n)\n    \n    # positives captured in the top leads, gains and lift\n    positives_in_top = top_leads['y'].sum()\n    gain = (positives_in_top / total_positives) * 100\n    lift = gain / random_gain\n    \n    gains.append(gain)\n    lifts.append(lift)\n\n\nplt.figure(figsize = (14, 5))\nplt.subplot(1, 2, 1)\nplt.plot(percentiles * 100, gains, color = 'blue', label = 'Normalized Gains')\nplt.plot([0, 100], [random_gain, random_gain], linestyle = '--', color = 'gray', label = 'Random')\nplt.title('Normalized Gains Curve')\nplt.xlabel('Top Percentage of Leads')\nplt.ylabel('Gains (%)')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(percentiles * 100, lifts, color = 'green', label = 'Lift Curve')\nplt.title('Lift Curve')\nplt.xlabel('Top Percentage of Leads')\nplt.ylabel('Lift')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:16:23.230850Z","iopub.execute_input":"2025-05-02T12:16:23.231190Z","iopub.status.idle":"2025-05-02T12:16:23.816193Z","shell.execute_reply.started":"2025-05-02T12:16:23.231166Z","shell.execute_reply":"2025-05-02T12:16:23.815379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation**  \n\nThe Gains curve clearly indicates that the majority of conversions are concentrated within the top 20% to 40% of leads. Anything after this range, results is almost no growth of gains, suggesting diminishing returns from targeting lower-ranked leads.   \n\nThe lift curve also shows similar information, with diminishing returns as population increases.","metadata":{}},{"cell_type":"code","source":"total_positives = y.sum()\n\ntop_percent = 0.40\ntop_n = int(len(scored_df) * top_percent)\n\ntop_leads = scored_df.head(top_n)\npositives_in_top = top_leads['y'].sum()\n\n# Calculate gains and lift\nrandom_gain = (total_positives / len(scored_df)) * 100\ngains = (positives_in_top / total_positives) * 100\nlift = gains / random_gain\n\n\nprint('#' * 81)\nprint('\\t\\t\\t\\t**FINAL NOTES**')\nprint(f'{gains:.2f}% of all conversions are captured by just the top {top_percent * 100}% of leads,')\nprint(f'and they are {lift:.2f} times more likely to convert than if we picked leads at random.')\nprint('#' * 81)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:16:23.817309Z","iopub.execute_input":"2025-05-02T12:16:23.817577Z","iopub.status.idle":"2025-05-02T12:16:23.824920Z","shell.execute_reply.started":"2025-05-02T12:16:23.817557Z","shell.execute_reply":"2025-05-02T12:16:23.823871Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Notes: Term Deposit Propensity Modeling\n\nThis analysis focused on optimising telephonic marketing campaigns for term deposit products by leveraging a robust propensity modeling approach. The goal was to identify high-likelihood conversion targets, thereby increasing campaign efficiency and ROI for the bank which led to the discovery of the fact that `83.54%` of all conversions are captured by just the top ***40.0%*** of leads, and they are `6.01` times more likely to convert than if leads are picked at random.\n\n**Key Findings**\n\n- **Past Campaign Effectiveness**: The historical conversion rate was 11.7%, aligning with industry norms for random targeting in direct marketing.\n- **Conversion Drivers**:\n    - *Demographics*: Older clients (30–60 years), those in management roles, singles, and those with tertiary education were more likely to subscribe.\n    - *Financial Status*: Higher account balances correlated with higher subscription rates.\n    - *Behavioral Factors*:\n        - Longer call durations were strongly associated with successful conversions.\n        - Fewer campaign contacts (1–3) were optimal; conversion rates dropped with excessive contact attempts.\n        - Recent prior contact (low `pdays`) and positive outcomes from previous campaigns (`poutcome`) significantly boosted conversion likelihood.\n    - *Channel and Timing*: Cellular contact outperformed telephone, and May was the most successful month for subscriptions.\n    - *Credit Status*: Clients without existing loans or defaults were more receptive.\n\n**Modeling \\& Data Handling**\n\n- Outliers in call duration, campaign contacts, and previous contacts were carefully excluded to prevent skewed modeling.\n- Categorical variables were encoded with attention to ordinal relationships (e.g., education, month).\n- Data balancing techniques (SMOTE, undersampling) were considered to address class imbalance.\n- Initial model was trained with a `train/test/calib` set to understand performance as well as impact of calibration on score alignment.\n- Final model was trained on the previously mentioned `train + test` set, then calibrated using original calibrated set and sigmoid method to better reflect true conversion likelihoods.\n\n\n## Recommendations\n\n**1. Targeted Outreach**\n\n- Prioritise segments with high predicted propensity: older, single, highly educated, management-level clients, and those with higher balances.\n- Focus on clients with no credit defaults or active loans.\n\n**2. Optimise Campaign Strategy**\n\n- Limit contact attempts to a maximum of 3 per client to avoid diminishing returns and potential customer fatigue.\n- Schedule campaigns to peak in May or other high-performing months identified in the analysis.\n- Favor cellular over telephone outreach for higher engagement.\n\n**3. Personalise Messaging**\n\n- Tailor scripts and offers for high-propensity segments (e.g., highlight product benefits relevant to management professionals or retirees).\n- For clients with prior positive campaign outcomes, reference past interactions to build rapport.\n\n**4. Enhance Data Quality \\& Monitoring**\n\n- Regularly review and update customer data to maintain segmentation accuracy.\n- Try to find out the education levels an outreach method of those currently unknown\n- Monitor for outliers and update exclusion thresholds as needed to keep the model robust.\n\n\n## A/B Testing Recommendations\n\nTo validate and further optimise these strategies, implement the following A/B tests:\n\n\n| Test Focus | Group A (Control) | Group B (Test) | Success Metric |\n| :-- | :-- | :-- | :-- |\n| Contact Channel | Telephone outreach | Cellular outreach | Conversion rate |\n| Campaign Timing | Standard months | May (peak month) | Conversion rate |\n| Contact Frequency | Up to 6 contacts | Max 3 contacts | Conversion rate, opt-out rate |\n| Personalisation | Generic script | Tailored script for high-propensity segments | Conversion rate, call duration |\n| Prior Campaign Targeting | All clients | Only clients with prior positive outcomes | Conversion rate |\n\n- **Monitor**: Conversion rates, call durations, and opt-out rates for each test group.\n- **Iterate**: Refine targeting and messaging based on statistical significance and observed lift.\n\n\n## Final Observations\n\n- The propensity model provides actionable insights for resource allocation and campaign design, enabling the bank to focus efforts on clients most likely to convert.\n- Regular calibration and monitoring are essential to adapt to changing customer behaviors and market conditions.\n- Combining data-driven targeting with thoughtful A/B testing will maximise marketing ROI and customer satisfaction.\n\n**NOTE**: This entire analysis is part of my weekly series in efforts to **demystify applied statistical techniques through real-world, project-driven examples**, making concepts like propensity modelling, causal inference, and evaluation metrics more accessible to practitioners of all backgrounds.","metadata":{"execution":{"iopub.status.busy":"2025-05-02T09:48:13.243063Z","iopub.execute_input":"2025-05-02T09:48:13.243468Z","iopub.status.idle":"2025-05-02T09:48:13.249487Z","shell.execute_reply.started":"2025-05-02T09:48:13.243443Z","shell.execute_reply":"2025-05-02T09:48:13.248233Z"}}},{"cell_type":"markdown","source":"# Let's connect!\n- [X](https://x.com/einsteinmuna)\n- [GitHub](https://github.com/munas-git)\n- [LinkedIn](https://www.linkedin.com/in/einstein-ebereonwu/)","metadata":{}}]}